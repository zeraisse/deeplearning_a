from transformers import pipeline

print("ğŸ¤– Chargement de ton IA...")
# On charge le dossier qu'on vient de crÃ©er
qa_pipeline = pipeline("question-answering", model="final_model", tokenizer="final_model", device=0)

while True:
    context = input("\nğŸ“œ Contexte : ")
    if not context: break
    question = input("â“ Question : ")
    
    result = qa_pipeline(question=question, context=context)
    print(f"ğŸ’¡ RÃ©ponse : {result['answer']} (Score: {result['score']:.4f})")